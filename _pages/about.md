---
permalink: /
title: "About Me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

<style>
.page__content p:first-of-type {
  margin-top: 1em;
}
</style>

Hi, I'm Sizhe (Alex) Xu ðŸ‘‹

I am a **Master of Science student** at **New York University**, working with Prof. [Takahiro Yabe][Takahiro Yabe-link] at the [RUN Lab][RUN lab-link]. My research interests lie at the intersection of **LLMs, Reinforcement Learning, Time-Series Prediction, and Computer Vision**, with a particular focus on their application in building smarter and more efficient cities now.

I am actively seeking **Ph.D.** opportunities for Fall 2026. I am eager to join a research group where I can contribute to developing next-generation intelligent systems and tackle fundamental challenges in areas like LLMs, Embodied AI and Urban Computing.

> ### Recent Highlights:
> * **Dec 2025:** I will be attending **NeurIPS 2025** in **San Diego**. 
> 
> * **Sept 2025:** Our paper, "[Abstain Mask Retain Core: Time Series Prediction by Adaptive Masking Loss][paper-link]," was accepted as a **Spotlight** poster at **NeurIPS 2025**.
> 
> Please feel free to reach out if you'd like to connect!

### Academic Journey

- Master of Science in Urban Data Science, New York University
  - Capstone mentored by [Takahiro Yabe][Takahiro Yabe-link].
- Bachelor of Engineering in Electronic Engineering, Dalian Jiaotong University
  - [Capstone][undergrad capstone-link] with [Prof. Jingjing Zong][ZJJ-link] & mentor [Shijie Jia][JSJ-link].

### Outside Research

My approach to technology is shaped by pursuits beyond the lab. You might find me in the kitchen experimenting with new recipesâ€”a process of creativity and precision not unlike building a model. I find a similar sense of structure and harmony in classical music, which reminds me of the elegance that can be found in complex systems. For a different kind of immersive challenge, I enjoy exploring the intricate world of *Elden Ring* and *Dark Souls III*. These interests, grounded in a long-standing engagement with philosophy, reinforce my core conviction: that our work as technologists should be thoughtfully crafted to serve and uplift humanity.

### Contact

- **Email**: sizhe [dot] xu [at] nyu [dot] edu

[Takahiro Yabe-link]: https://engineering.nyu.edu/faculty/takahiro-yabe
[paper-link]: ../files/27228_Abstain_Mask_Retain_Core.pdf
[RUN lab-link]: https://www.takayabe.net/
[undergrad capstone-link]: https://github.com/MazelTovy/image_segmentation_beamer
[ZJJ-link]: http://srie.djtu.edu.cn/162.html
[JSJ-link]: http://www.djtu.edu.cn/teacher/43.html

<!-- I am a Master Student at **New York University**, with a deep research interest in building autonomous agents capable of understanding, reasoning, and interacting with complex, dynamic environments. My goal is to contribute to the development of Embodied AI and World Models, bridging the gap between digital intelligence and the physical world.

My research approach is demonstrated in my co-first author paper, "Abstain Mask Retain Core: Time Series Prediction by Adaptive Masking Loss," which will be presented as a **Spotlight (Top 5%)** at **NeurIPS 2025**. In this work, we challenged the conventional "long-sequence information gain" hypothesis in time series forecasting. We proposed the AMRC framework, grounded in information bottleneck theory, which adaptively masks redundant information to enhance prediction accuracy and representation stability. This work underscores my ability to question established assumptions and develop novel, principled machine learning solutions.

Beyond foundational model research, I am passionate about applying these principles to create intelligent systems. I explored high-level decision-making by developing the "Thinking on the Move (TOM)" framework, which uses LLM-powered agents to simulate complex human mobility behaviors in urban settings. My hands-on experience extends to low-level control and perception, where I led a team to win the First Prize in the National Smart Car Competition by engineering an autonomous vehicle from the ground up, integrating custom hardware, control systems, and computer vision models.

I am currently seeking a **Ph.D. position** where I can leverage my background in machine learning, agent-based modeling, and robotics to tackle fundamental challenges in building next-generation intelligent agents. I am particularly excited about research in Vision-Language-Action (VLA) models, reinforcement learning with human feedback, and the scalability of world models. -->
